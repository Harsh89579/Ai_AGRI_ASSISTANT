An AI-powered agriculture assistant designed for Indian farmers, built with a production-grade microservices architecture.
The system follows a RAG-first, LLM-fallback strategy to ensure reliable, cost-effective, and explainable answers.

ğŸ§  â€œDatabase se jankari mile to wahi do, warna LLM se intelligent jawab lao.â€

##ğŸš€ Key Highlights

âœ… RAG-first architecture (LLM sirf tab jab data na mile)

âœ… Free cloud LLM (Groq) â€“ no OpenAI cost

âœ… Dockerized microservices

âœ… Circuit breaker + weak response detection

âœ… Hinglish farmer-friendly responses

âœ… Session-based chat history

âœ… Production-ready backend design

##ğŸ—ï¸ System Architecture

 Client (UI / API)
      â”‚
      â–¼
API Gateway
      â”‚
      â–¼
Chat Orchestrator
  â”œâ”€â”€ NLU Service (Intent + Crop detection)
  â”œâ”€â”€ RAG Service (SQLite knowledge base)
  â””â”€â”€ LLM Service (Groq Cloud)
         â”œâ”€â”€ Circuit Breaker
         â”œâ”€â”€ Prompt Guardrails
         â””â”€â”€ Weak Response Filter

##ğŸ§© Microservices Overview
Service	Responsibility
API Gateway	Single entry point, routing & CORS
Chat Orchestrator	Controls full conversation flow
NLU Service	Rule-based intent & crop detection
RAG Service	Knowledge lookup from SQLite DB
LLM Service	Groq LLM calls with safety controls

##ğŸ” Request Flow (RAG-First Logic)

User sends message

NLU â†’ Detect intent & crop

RAG â†’ Search local knowledge base

If data found â†’ return RAG answer

Else â†’ call LLM (Groq)

If LLM weak/fails â†’ safe fallback response

Save full chat history

##ğŸ› ï¸ Tech Stack

Backend: FastAPI, Python

LLM: Groq (llama-3.1-8b-instant)

Database: SQLite (RAG)

Containerization: Docker, Docker Compose

Monitoring: Prometheus metrics

Testing: Pytest, HTTPX

Language: Hinglish (Hindi + English)

##ğŸ“¦ Project Structure
 backend/
â””â”€â”€ services/
    â”œâ”€â”€ api_gateway/
    â”œâ”€â”€ chat_orchestrator/
    â”œâ”€â”€ nlu_llm/
    â”œâ”€â”€ rag_services/
    â”œâ”€â”€ llm-services/
    â”œâ”€â”€ docker-compose.yml
    â””â”€â”€ .env


##ğŸ³ Run with Docker (Recommended)
docker compose build
docker compose up -d

##Services will be available on:

API Gateway â†’ http://localhost:8000

Swagger Docs â†’ http://localhost:8000/docs

##ğŸŒ± Future Enhancements

ğŸ¤ Voice input/output (STT + TTS)

ğŸŒ Frontend (Streamlit / React)

ğŸ“„ PDF & Govt advisory ingestion (advanced RAG)

ğŸ“Š Grafana dashboards

ğŸŒ Multi-language support

##ğŸ† What This Project Demonstrates

Production-grade AI backend design

Microservices orchestration

Practical RAG implementation

Real-world debugging & cloud LLM usage

Scalable, interview-ready system

##ğŸ‘¨â€ğŸ’» Author

Harsh Tripathi
AI / Backend / Applied LLM Systems
